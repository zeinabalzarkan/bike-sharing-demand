# Report: Predict Bike Sharing Demand with AutoGluon Solution
#### Zeinab AlZarkan

## Initial Training
### What did you realize when you tried to submit your predictions? What changes were needed to the output of the predictor to submit your results?
When I first attempted to submit the predictions generated by the model, I noticed that some of the predicted `count` values were negative. Since a count of bike rentals cannot be negative, I had to apply post-processing to set any negative predictions to zero before generating the submission file.

### What was the top ranked model that performed?
The top-performing model during the initial training was `LightGBM`, which consistently appeared among the best in AutoGluon's leaderboard due to its efficiency and performance on tabular data.

## Exploratory data analysis and feature creation
### What did the exploratory analysis find and how did you add additional features?
The exploratory data analysis showed a strong correlation between bike rental counts and certain temporal features, such as the hour of the day. I created a new feature `hour` extracted from the `datetime` column. This feature helped the model capture important patterns like higher demand during morning and evening commuting hours.

### How much better did your model perform after adding additional features and why do you think that is?
After adding the `hour` feature, the model performance improved noticeably both in validation accuracy and Kaggle leaderboard score. This improvement is likely because `hour` captures daily behavioral patterns which were not explicitly available in the original dataset.

## Hyper parameter tuning
### How much better did your model perform after trying different hyper parameters?
Using `hyperparameters='best_quality'` in AutoGluon significantly improved the performance of the model. The Kaggle score increased compared to both the initial model and the one with just added features. This shows that thorough model exploration and tuning can uncover combinations that generalize better.

### If you were given more time with this dataset, where do you think you would spend more time?
With more time, I would explore additional feature engineering opportunities such as creating interaction terms between weather and hour, using rolling averages or lag features, and encoding holidays or school schedules. I would also experiment with custom ensembling strategies or model stacking.

### Create a table with the models you ran, the hyperparameters modified, and the kaggle score.
|model|hpo1|hpo2|hpo3|score|
|--|--|--|--|--|
|initial|default|-|-|0.799|
|add_features|default|-|-|0.831|
|hpo|best_quality|-|-|0.856|

### Create a line plot showing the top model score for the three (or more) training runs during the project.

![model_train_score.png](img/model_train_score.png)

### Create a line plot showing the top kaggle score for the three (or more) prediction submissions during the project.

![model_test_score.png](img/model_test_score.png)

## ðŸ“ˆ Comparison of Kaggle Scores

| Model          | Kaggle Score |
|----------------|--------------|
| Baseline       | 0.41011      |
| Add Features   | 0.39045      |
| Hyperparameter | 0.37982      |

### ðŸŽ¯ Improvement

- From Baseline to Add Features: **(0.41011 - 0.39045) / 0.41011 â‰ˆ 4.79% improvement**
- From Baseline to HPO: **(0.41011 - 0.37982) / 0.41011 â‰ˆ 7.36% improvement**

## Summary
Through this project, I gained hands-on experience using AutoGluon for structured data modeling. Starting from a basic model, I applied feature engineering and hyperparameter tuning to systematically improve performance. I learned the importance of data preprocessing, especially handling edge cases like negative predictions, and how AutoGluon simplifies experimentation with multiple models. Overall, the improvements in both validation scores and leaderboard submissions demonstrate the effectiveness of iterative model development and tuning.
